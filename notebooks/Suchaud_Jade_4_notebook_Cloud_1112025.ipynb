{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd66e89",
   "metadata": {},
   "source": [
    "# Classification fruits avec MobileNetV2 sur cluster EMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60c6348f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>45</td><td>application_1763712756826_0046</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-37-33.eu-central-1.compute.internal:20888/proxy/application_1763712756826_0046/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-36-103.eu-central-1.compute.internal:8042/node/containerlogs/container_1763712756826_0046_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version: 3.5.6-amzn-1\n",
      "Application ID: application_1763712756826_0046"
     ]
    }
   ],
   "source": [
    "print(f\"Spark Version: {spark.version}\")\n",
    "print(f\"Application ID: {spark.sparkContext.applicationId}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cebd63cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RDD count: 5"
     ]
    }
   ],
   "source": [
    "simple_rdd = spark.sparkContext.parallelize([1, 2, 3, 4, 5])\n",
    "result = simple_rdd.count()\n",
    "print(f\"Test RDD count: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a21d564",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration AWS S3\n",
      "Bucket: p8-fruits-jademayalb\n",
      "Data: s3://p8-fruits-jademayalb/Test\n",
      "Results: s3://p8-fruits-jademayalb/Results"
     ]
    }
   ],
   "source": [
    "# Configuration S3\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "BUCKET_NAME = \"p8-fruits-jademayalb\"\n",
    "PATH_Data = f's3://{BUCKET_NAME}/Test'\n",
    "PATH_Result = f's3://{BUCKET_NAME}/Results'\n",
    "PATH_Result_PCA = f's3://{BUCKET_NAME}/Results_PCA'\n",
    "\n",
    "print(\"Configuration AWS S3\")\n",
    "print(f\"Bucket: {BUCKET_NAME}\")\n",
    "print(f\"Data: {PATH_Data}\")\n",
    "print(f\"Results: {PATH_Result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce2ccbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement images depuis S3...\n",
      "Comptage images...\n",
      "Images trouv?es: 22687"
     ]
    }
   ],
   "source": [
    "# Chargement données\n",
    "images = spark.read.format(\"binaryFile\") \\\n",
    "    .option(\"pathGlobFilter\", \"*.jpg\") \\\n",
    "    .option(\"recursiveFileLookup\", \"true\") \\\n",
    "    .load(PATH_Data)\n",
    "\n",
    "print(\"Comptage images...\")\n",
    "image_count = images.count()\n",
    "print(f\"Images trouvées: {image_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6380441b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- modificationTime: timestamp (nullable = true)\n",
      " |-- length: long (nullable = true)\n",
      " |-- content: binary (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      "\n",
      "+-------------------------------------------------------+----------+\n",
      "|path                                                   |label     |\n",
      "+-------------------------------------------------------+----------+\n",
      "|s3://p8-fruits-jademayalb/Test/Watermelon/r_106_100.jpg|Watermelon|\n",
      "|s3://p8-fruits-jademayalb/Test/Watermelon/r_109_100.jpg|Watermelon|\n",
      "|s3://p8-fruits-jademayalb/Test/Watermelon/r_108_100.jpg|Watermelon|\n",
      "|s3://p8-fruits-jademayalb/Test/Watermelon/r_107_100.jpg|Watermelon|\n",
      "|s3://p8-fruits-jademayalb/Test/Watermelon/r_95_100.jpg |Watermelon|\n",
      "+-------------------------------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------+-----+\n",
      "|         label|count|\n",
      "+--------------+-----+\n",
      "|    Watermelon|  157|\n",
      "|Pineapple Mini|  163|\n",
      "|   Cauliflower|  234|\n",
      "| Cucumber Ripe|  130|\n",
      "|     Raspberry|  166|\n",
      "|     Pineapple|  166|\n",
      "|Apple Golden 1|  160|\n",
      "|   Onion White|  146|\n",
      "|      Rambutan|  164|\n",
      "|        Pear 2|  232|\n",
      "|  Pear Forelle|  234|\n",
      "|      Pear Red|  222|\n",
      "|        Lychee|  166|\n",
      "|     Nectarine|  164|\n",
      "|      Beetroot|  150|\n",
      "|     Mandarine|  166|\n",
      "| Pepper Orange|  234|\n",
      "|  Cantaloupe 2|  164|\n",
      "|    Strawberry|  164|\n",
      "|  Cantaloupe 1|  164|\n",
      "+--------------+-----+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import element_at, split\n",
    "\n",
    "# Extraction du nom de dossier comme label\n",
    "images = images.withColumn('label', element_at(split(images['path'], '/'),-2))\n",
    "\n",
    "# Vérification\n",
    "images.printSchema()\n",
    "images.select('path','label').show(5, False)\n",
    "\n",
    "# Distribution des classes\n",
    "images.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eb640e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 22687\n",
      "Fraction: 0.132\n",
      "?chantillon: 3000 images\n",
      "Top 10 classes ?chantillon:\n",
      "+------------------+-----+\n",
      "|             label|count|\n",
      "+------------------+-----+\n",
      "|     Pepper Orange|   53|\n",
      "|               Fig|   50|\n",
      "|          Tomato 3|   43|\n",
      "|       Cauliflower|   42|\n",
      "|            Walnut|   42|\n",
      "|          Tomato 1|   42|\n",
      "|Melon Piel de Sapo|   41|\n",
      "|        Pear Stone|   40|\n",
      "|  Strawberry Wedge|   39|\n",
      "|        Clementine|   37|\n",
      "+------------------+-----+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "# Cache et comptage\n",
    "images.cache()\n",
    "total_images = images.count()\n",
    "print(f\"Total images: {total_images}\")\n",
    "\n",
    "# Échantillonnage \n",
    "target_sample = 3000\n",
    "sample_fraction = target_sample / total_images\n",
    "\n",
    "print(f\"Fraction: {sample_fraction:.3f}\")\n",
    "\n",
    "# Échantillonnage \n",
    "sampled_images = images.sample(withReplacement=False, \n",
    "                              fraction=sample_fraction * 1.2, \n",
    "                              seed=42).limit(target_sample)\n",
    "\n",
    "# Vérification \n",
    "final_count = sampled_images.count()\n",
    "print(f\"Échantillon: {final_count} images\")\n",
    "\n",
    "# Distribution \n",
    "print(\"Top 10 classes échantillon:\")\n",
    "sampled_images.groupBy('label').count().orderBy('count', ascending=False).show(10)\n",
    "\n",
    "# Remplacement\n",
    "images = sampled_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74288abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Nettoyage modules TensorFlow\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import importlib\n",
    "\n",
    "modules_to_clean = [name for name in sys.modules.keys() \n",
    "                   if any(x in name.lower() for x in ['tensorflow', 'keras', 'tf', 'optree'])]\n",
    "\n",
    "for module in modules_to_clean:\n",
    "    if module in sys.modules:\n",
    "        del sys.modules[module]\n",
    "\n",
    "gc.collect()\n",
    "importlib.invalidate_caches()\n",
    "\n",
    "# Configuration paths\n",
    "paths_to_add = [\n",
    "    '/tmp/python_packages',\n",
    "    '/tmp/python_user/lib/python3.9/site-packages',\n",
    "    '/usr/local/lib64/python3.9/site-packages',\n",
    "    '/usr/local/lib/python3.9/site-packages'\n",
    "]\n",
    "\n",
    "for path in paths_to_add:\n",
    "    if os.path.exists(path) and path not in sys.path:\n",
    "        sys.path.insert(0, path)\n",
    "\n",
    "# Variables d'environnement\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f3892d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imports TensorFlow\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np\n",
    "import io\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2cc1476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialisation MobileNetV2...\n",
      "MobileNetV2 charg?: (None, 1000)\n",
      "Feature model: (None, 1280)\n",
      "Layers broadcast?s: 260\n",
      "Taille m?moire: 8.6 MB"
     ]
    }
   ],
   "source": [
    "# Modèle MobileNetV2\n",
    "model = MobileNetV2(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\n",
    "print(f\"MobileNetV2 chargé: {model.output_shape}\")\n",
    "\n",
    "# Feature extractor (1280D)\n",
    "feature_model = Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "print(f\"Feature model: {feature_model.output_shape}\")\n",
    "\n",
    "# Broadcast weights pour optimisation\n",
    "model_weights = feature_model.get_weights()\n",
    "weights_size_mb = sum(w.nbytes for w in model_weights) / (1024*1024)\n",
    "weights_broadcast = spark.sparkContext.broadcast(model_weights)\n",
    "\n",
    "print(f\"Layers broadcastés: {len(model_weights)}\")\n",
    "print(f\"Taille mémoire: {weights_size_mb:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c170c83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images ?chantillon: 3000\n",
      "Batch size: 100\n",
      "Total batches: 30\n",
      "Temps estim?: 2.5 minutes\n",
      "Batch 5/30 | Progress: 500/3000 (16.7%) | Rate: 16.6 img/s | ETA: 2.5min\n",
      "Batch 10/30 | Progress: 1000/3000 (33.3%) | Rate: 17.2 img/s | ETA: 1.9min\n",
      "Batch 15/30 | Progress: 1500/3000 (50.0%) | Rate: 17.2 img/s | ETA: 1.5min\n",
      "Batch 20/30 | Progress: 2000/3000 (66.7%) | Rate: 17.2 img/s | ETA: 1.0min\n",
      "Batch 25/30 | Progress: 2500/3000 (83.3%) | Rate: 17.3 img/s | ETA: 0.5min\n",
      "Batch 30/30 | Progress: 3000/3000 (100.0%) | Rate: 17.5 img/s | ETA: 0.0min\n",
      "Images trait?es: 3000\n",
      "Images ?chou?es: 0\n",
      "Temps total: 171.3s (2.9 min)\n",
      "Performance: 17.5 img/sec\n",
      "DataFrame cr??: 3000 lignes\n",
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      " |-- features: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      "\n",
      "+-------------------------------------------------------+----------+\n",
      "|path                                                   |label     |\n",
      "+-------------------------------------------------------+----------+\n",
      "|s3://p8-fruits-jademayalb/Test/Watermelon/r_94_100.jpg |Watermelon|\n",
      "|s3://p8-fruits-jademayalb/Test/Watermelon/r_80_100.jpg |Watermelon|\n",
      "|s3://p8-fruits-jademayalb/Test/Watermelon/r_173_100.jpg|Watermelon|\n",
      "|s3://p8-fruits-jademayalb/Test/Watermelon/r_96_100.jpg |Watermelon|\n",
      "|s3://p8-fruits-jademayalb/Test/Watermelon/r_111_100.jpg|Watermelon|\n",
      "+-------------------------------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "PCA termin?: 10.1s\n",
      "Variance totale: 0.8446 (84.46%)\n",
      "Variance 10 comp: 0.4539 (45.39%)\n",
      "Variance 50 comp: 0.7442 (74.42%)\n",
      "Sauvegarde termin?e: 4.1s\n",
      "Features 1280D: 3000 lignes\n",
      "Features PCA 100D: 3000 lignes\n",
      "Structure PCA:\n",
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      " |-- pca_features: vector (nullable = true)\n",
      "\n",
      "+----------------------------------------------------------+------------+\n",
      "|path                                                      |label       |\n",
      "+----------------------------------------------------------+------------+\n",
      "|s3://p8-fruits-jademayalb/Test/Peach/62_100.jpg           |Peach       |\n",
      "|s3://p8-fruits-jademayalb/Test/Strawberry/r_80_100.jpg    |Strawberry  |\n",
      "|s3://p8-fruits-jademayalb/Test/Walnut/r_184_100.jpg       |Walnut      |\n",
      "|s3://p8-fruits-jademayalb/Test/Walnut/r_3_100.jpg         |Walnut      |\n",
      "|s3://p8-fruits-jademayalb/Test/Tomato Heart/r2_281_100.jpg|Tomato Heart|\n",
      "+----------------------------------------------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "M?tadonn?es: 12 param?tres\n",
      "+--------------------------+-------------------+\n",
      "|parameter                 |value              |\n",
      "+--------------------------+-------------------+\n",
      "|experiment_date           |2025-11-21 18:16:39|\n",
      "|sample_size               |3000               |\n",
      "|extraction_time_minutes   |2.8546229203542075 |\n",
      "|pca_time_seconds          |10.124796867370605 |\n",
      "|performance_img_per_sec   |17.515448237834473 |\n",
      "|pca_variance_explained    |0.8446457584529482 |\n",
      "|model_used                |MobileNetV2        |\n",
      "|feature_dimension_original|1280               |\n",
      "|feature_dimension_pca     |100                |\n",
      "|batch_size                |100                |\n",
      "|errors_count              |0                  |\n",
      "|sampling_method           |simple_random      |\n",
      "+--------------------------+-------------------+\n",
      "\n",
      "Images trait?es: 3,000\n",
      "Temps extraction: 2.9 minutes\n",
      "Temps PCA: 10.1 secondes\n",
      "Temps total: 3.2 minutes\n",
      "Performance: 17.5 img/s\n",
      "- Features 1280D: s3://p8-fruits-jademayalb/Results_Sample_3k\n",
      "- Features PCA 100D: s3://p8-fruits-jademayalb/Results_PCA_Sample_3k\n",
      "- M?tadonn?es: s3://p8-fruits-jademayalb/Metadata_Sample_3k\n",
      "\n",
      "Termin?: 2025-11-21 18:16:41"
     ]
    }
   ],
   "source": [
    "#  Extraction features sur échantillon\n",
    "import time\n",
    "\n",
    "batch_size = 100\n",
    "extraction_start = time.time()\n",
    "\n",
    "image_paths = images.select(\"path\", \"label\").collect()\n",
    "total_sample = len(image_paths)\n",
    "total_batches = (total_sample + batch_size - 1) // batch_size\n",
    "\n",
    "print(f\"Images échantillon: {total_sample}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Total batches: {total_batches}\")\n",
    "print(f\"Temps estimé: {(total_sample / 20) / 60:.1f} minutes\")\n",
    "\n",
    "# Initialisation\n",
    "all_features = []\n",
    "all_labels = []\n",
    "all_paths = []\n",
    "errors_count = 0\n",
    "\n",
    "# Processing par batch\n",
    "for batch_start in range(0, total_sample, batch_size):\n",
    "    batch_end = min(batch_start + batch_size, total_sample)\n",
    "    batch_paths = image_paths[batch_start:batch_end]\n",
    "    \n",
    "    batch_num = batch_start // batch_size + 1\n",
    "    \n",
    "    try:\n",
    "        # Chargement batch S3\n",
    "        current_paths = [item['path'] for item in batch_paths]\n",
    "        batch_df = spark.read.format(\"binaryFile\").load(current_paths)\n",
    "        batch_data = batch_df.select(\"path\", \"content\").collect()\n",
    "        \n",
    "        # Preprocessing images\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        batch_paths_clean = []\n",
    "        \n",
    "        for data_item in batch_data:\n",
    "            try:\n",
    "                path_item = next(p for p in batch_paths if p['path'] == data_item['path'])\n",
    "                \n",
    "                img = Image.open(io.BytesIO(data_item['content'])).resize((224, 224))\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "                \n",
    "                img_array = img_to_array(img)\n",
    "                batch_images.append(preprocess_input(img_array))\n",
    "                batch_labels.append(path_item['label'])\n",
    "                batch_paths_clean.append(data_item['path'])\n",
    "                \n",
    "            except Exception:\n",
    "                errors_count += 1\n",
    "                continue\n",
    "        \n",
    "        # Extraction features MobileNetV2\n",
    "        if batch_images:\n",
    "            batch_input = np.stack(batch_images)\n",
    "            features = feature_model.predict(batch_input, verbose=0)\n",
    "            \n",
    "            all_features.extend([f.flatten().tolist() for f in features])\n",
    "            all_labels.extend(batch_labels)\n",
    "            all_paths.extend(batch_paths_clean)\n",
    "        \n",
    "        # Progress monitoring\n",
    "        elapsed = time.time() - extraction_start\n",
    "        processed = len(all_features)\n",
    "        rate = processed / elapsed if elapsed > 0 else 0\n",
    "        \n",
    "        if batch_num % 5 == 0 or batch_num == total_batches:\n",
    "            remaining = total_sample - processed\n",
    "            eta_minutes = (remaining / rate / 60) if rate > 0 else 0\n",
    "            progress_pct = (processed / total_sample) * 100\n",
    "            \n",
    "            print(f\"Batch {batch_num}/{total_batches} | \" +\n",
    "                  f\"Progress: {processed}/{total_sample} ({progress_pct:.1f}%) | \" +\n",
    "                  f\"Rate: {rate:.1f} img/s | \" +\n",
    "                  f\"ETA: {eta_minutes:.1f}min\")\n",
    "        \n",
    "        # Nettoyage mémoire\n",
    "        del batch_data, batch_images\n",
    "        if 'batch_input' in locals():\n",
    "            del batch_input, features\n",
    "        gc.collect()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur batch {batch_num}: {str(e)[:60]}\")\n",
    "        errors_count += len(batch_paths)\n",
    "        continue\n",
    "\n",
    "# Résultats extraction\n",
    "extraction_time = time.time() - extraction_start\n",
    "successful_images = len(all_features)\n",
    "\n",
    "print(f\"Images traitées: {successful_images}\")\n",
    "print(f\"Images échouées: {errors_count}\")\n",
    "print(f\"Temps total: {extraction_time:.1f}s ({extraction_time/60:.1f} min)\")\n",
    "print(f\"Performance: {successful_images/extraction_time:.1f} img/sec\")\n",
    "\n",
    "if successful_images == 0:\n",
    "    print(\"ERREUR: Aucune image traitée\")\n",
    "    exit()\n",
    "\n",
    "# Création DataFrame Spark\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType, FloatType\n",
    "\n",
    "schema_features = StructType([\n",
    "    StructField(\"path\", StringType(), True),\n",
    "    StructField(\"label\", StringType(), True),\n",
    "    StructField(\"features\", ArrayType(FloatType()), True)\n",
    "])\n",
    "\n",
    "data_rows = list(zip(all_paths, all_labels, all_features))\n",
    "df_features = spark.createDataFrame(data_rows, schema_features)\n",
    "df_features.cache()\n",
    "\n",
    "feature_count = df_features.count()\n",
    "print(f\"DataFrame créé: {feature_count} lignes\")\n",
    "\n",
    "# Vérification structure\n",
    "df_features.printSchema()\n",
    "df_features.select(\"path\", \"label\").show(5, False)\n",
    "\n",
    "# PCA 1280D -> 100D\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "pca_start = time.time()\n",
    "\n",
    "def array_to_vector(arr):\n",
    "    return Vectors.dense(arr)\n",
    "\n",
    "vector_udf = udf(array_to_vector, VectorUDT())\n",
    "\n",
    "df_vectors = df_features.withColumn(\"features_vector\", vector_udf(\"features\"))\n",
    "\n",
    "pca = PCA(k=100, inputCol=\"features_vector\", outputCol=\"pca_features\")\n",
    "pca_model = pca.fit(df_vectors)\n",
    "\n",
    "df_pca = pca_model.transform(df_vectors)\n",
    "df_final = df_pca.select(\"path\", \"label\", \"pca_features\")\n",
    "\n",
    "pca_time = time.time() - pca_start\n",
    "print(f\"PCA terminé: {pca_time:.1f}s\")\n",
    "\n",
    "# Analyse variance expliquée\n",
    "explained_variance = pca_model.explainedVariance\n",
    "total_variance = sum(explained_variance)\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "print(f\"Variance totale: {total_variance:.4f} ({total_variance*100:.2f}%)\")\n",
    "print(f\"Variance 10 comp: {cumulative_variance[9]:.4f} ({cumulative_variance[9]*100:.2f}%)\")\n",
    "print(f\"Variance 50 comp: {cumulative_variance[49]:.4f} ({cumulative_variance[49]*100:.2f}%)\")\n",
    "\n",
    "# Sauvegarde S3\n",
    "PATH_Result_Sample = f's3://{BUCKET_NAME}/Results_Sample_3k'\n",
    "PATH_Result_PCA_Sample = f's3://{BUCKET_NAME}/Results_PCA_Sample_3k'\n",
    "PATH_Metadata_Sample = f's3://{BUCKET_NAME}/Metadata_Sample_3k'\n",
    "\n",
    "save_start = time.time()\n",
    "\n",
    "try:\n",
    "    df_features.write.mode(\"overwrite\").parquet(PATH_Result_Sample)\n",
    "    \n",
    "    df_final.write.mode(\"overwrite\").parquet(PATH_Result_PCA_Sample)\n",
    "    \n",
    "    # Métadonnées expérience\n",
    "    from datetime import datetime\n",
    "    \n",
    "    metadata_data = [\n",
    "        (\"experiment_date\", datetime.now().strftime('%Y-%m-%d %H:%M:%S')),\n",
    "        (\"sample_size\", str(successful_images)),\n",
    "        (\"extraction_time_minutes\", str(extraction_time/60)),\n",
    "        (\"pca_time_seconds\", str(pca_time)),\n",
    "        (\"performance_img_per_sec\", str(successful_images/extraction_time)),\n",
    "        (\"pca_variance_explained\", str(total_variance)),\n",
    "        (\"model_used\", \"MobileNetV2\"),\n",
    "        (\"feature_dimension_original\", \"1280\"),\n",
    "        (\"feature_dimension_pca\", \"100\"),\n",
    "        (\"batch_size\", str(batch_size)),\n",
    "        (\"errors_count\", str(errors_count)),\n",
    "        (\"sampling_method\", \"simple_random\")\n",
    "    ]\n",
    "    \n",
    "    schema_metadata = StructType([\n",
    "        StructField(\"parameter\", StringType(), True),\n",
    "        StructField(\"value\", StringType(), True)\n",
    "    ])\n",
    "    \n",
    "    df_metadata = spark.createDataFrame(metadata_data, schema_metadata)\n",
    "    df_metadata.write.mode(\"overwrite\").parquet(PATH_Metadata_Sample)\n",
    "    \n",
    "    save_time = time.time() - save_start\n",
    "    print(f\"Sauvegarde terminée: {save_time:.1f}s\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erreur sauvegarde: {e}\")\n",
    "\n",
    "# Vérification finale\n",
    "try:\n",
    "    test_features = spark.read.parquet(PATH_Result_Sample)\n",
    "    features_count = test_features.count()\n",
    "    print(f\"Features 1280D: {features_count} lignes\")\n",
    "    \n",
    "    test_pca = spark.read.parquet(PATH_Result_PCA_Sample)\n",
    "    pca_count = test_pca.count()\n",
    "    print(f\"Features PCA 100D: {pca_count} lignes\")\n",
    "    \n",
    "    print(\"Structure PCA:\")\n",
    "    test_pca.printSchema()\n",
    "    test_pca.select(\"path\", \"label\").show(5, False)\n",
    "    \n",
    "    test_metadata = spark.read.parquet(PATH_Metadata_Sample)\n",
    "    print(f\"Métadonnées: {test_metadata.count()} paramètres\")\n",
    "    test_metadata.show(15, False)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erreur vérification: {e}\")\n",
    "\n",
    "# Résultats finaux\n",
    "total_pipeline_time = time.time() - extraction_start\n",
    "\n",
    "print(f\"Images traitées: {successful_images:,}\")\n",
    "print(f\"Temps extraction: {extraction_time/60:.1f} minutes\")\n",
    "print(f\"Temps PCA: {pca_time:.1f} secondes\")\n",
    "print(f\"Temps total: {total_pipeline_time/60:.1f} minutes\")\n",
    "print(f\"Performance: {successful_images/extraction_time:.1f} img/s\")\n",
    "\n",
    "print(f\"- Features 1280D: {PATH_Result_Sample}\")\n",
    "print(f\"- Features PCA 100D: {PATH_Result_PCA_Sample}\")\n",
    "print(f\"- Métadonnées: {PATH_Metadata_Sample}\")\n",
    "\n",
    "print(f\"\\nTerminé: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e3dc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
